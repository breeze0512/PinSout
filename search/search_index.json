{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Getting Start This document describes the procedure for running MovingFeature Service. 1. Procedure for executing Moving Feature Service This service will operate in the following environments: MovingFeature Service Running Environment Essential Environment Version Java OpenJDK8 Apache Spark Apache Spark 2.4.3 Cassandra Cassandra 3.11.3 Stratio's Cassandra Lucene Index cassandra-lucene-index 3.11.3 The user can obtain the detailed information for installing Cassandra from the 2. Build Cassandra and set up extended library part The user must connect to Cassandra before the server is starting The user can obtain the detailed information for installing Apache Spark from the 3. Build Apache Spark part 1.1 Building MovingFeature Service This service is provided as a zip file. To extract the zip file from the machine on which the service runs. $ unzip mfjson.zip MovingFeature Service Directory Configuration MovingFeature Service File List Information for Service File Created File Version run_noatuh.sh Executable file without pntml (Execute on Local system) run_pntml.sh Executable file with pntml application.yaml Web Configuration File engine.yaml Engine Configuration File (Apache Spark) store.yaml Store Configuration File (Cassandra) drop-keyspaces.cql Delete Existing Data CQL initialize-auth.cql Generation the unique user id for Cassandra initialize-data.cql Cassandra Initialization CQL insert-users.cql Cassandra Initialization CQL job-result.cql Cassandra Initialization CQL movingfeature-web-0.3.0-SNAPSHOT.jar MovingFeature Service Main The following files must be edited for your environment prior to running the service: \u2192 Web configuration file : mfjson/bin/config/application.yaml \u2192 Engine configuration file : mfjson/bin/config/engine.yaml \u2192 Store configuration file : mfjson/bin/config/store.yaml 1.1.1 To set up a Web configuration file Web settings by editing the < mfjosn/bin/config/application.yaml >. Configuring Moving Features Service URLs Set the server address for the user to access the Moving Features Service. movingfeature : url : \"Moving Features Service URL\" Service URL Configuration Example 1.1.2 To set up a store configuration file Store settings are done by editing < mfjson/bin/config/store.yaml >. Before configuring this configuration, create a Cassandra environment. Reference: Building 2 Cassandra and Configuring Extended Libraries. Configuring Cassandra to Connect Configure the connection destination for Cassandra to store data. nodes : - host : \"HostName or IP address\" port : \"Port Number\" Cassandra Configuration Example Access User Settings If you have limited access to Cassandra, you must configure a username and password for the user who can access it. authentication : user : \"UserName\" password : \"Password\" 1.1.3 To set up a engine configuration file Engine settings are done by editing < mfjson/bin/config/engine.yaml >. Before configuring this configuration, create a Apache Spark environment. Reference: Building 3 Apache Spark . Configuring Apache Spark to Connect Configure the connection destination for Cassandra to store data. Apache Spark Configuration Example Information of the setting items For more detailed information, please refer to the Spark Configuration section of the official document. Link for Spark Configuration spark : home : master : # Run Spark locally with as many worker threads as logical cores on your machine. appname : # The name of your application. This will appear in the UI and in log data. deploymode : # The deploy mode of Spark driver program, either \"client\" or \"cluster\", Which means to launch driver program locally (\"client\") or remotely (\"cluster\") on one of the nodes inside the cluster. verbose : # Print out fine-grained debugging information by running spark-submit conf : - key : \"spark.default.parallelism\" value : # Default number of partitions in RDDs returned by transformations like join, reduceByKey, and parallelize when not set by user - key : \"spark.executor.cores\" value : # Number of virtual cores - key : \"spark.executor.memory\" value : # Size of memory to use for each executor that runs the task - key : \"spark.driver.memory\" value : # Size of memory to use for the driver - key : \"spark.driver.cores\" value : # Number of virtual cores to use for the driver - key : \"spark.driver.maxResultSize\" value : # Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. Should be at least 1M, or 0 for unlimited. - key : \"spark.driver.port\" value : # Port for the driver to listen on - key : \"spark.blockManager.port\" value : # Port for all block managers to listen on - key : \"spark.driver.blockManager.port\" value : # Driver-specific port for the block manager to listen on, for cases where it cannot use the same configuration as executors. - key : \"spark.broadcast.port\" value : # Port for the driver's HTTP broadcast server to listen on. - key : \"spark.cores.max\" value : # The maximum amount of CPU cores to request for the application from across the cluster - key : \"spark.rpc.message.maxSize\" value : # Maximum message size (in MiB) to allow in \"control plane\" communication jarsPath : ../sparkjars serverClassPath : /mnt/PnTML/MF/lib/ parallel : 1 # threads of job lastScanSecond : 0.1 Example for configuration spark : home : master : local[*] appname : movingfeature- deploymode : client verbose : true conf : - key : \"spark.default.parallelism\" value : 20 - key : \"spark.executor.cores\" value : 2 - key : \"spark.executor.memory\" value : 10g - key : \"spark.driver.memory\" value : 10g - key : \"spark.driver.cores\" value : 2 - key : \"spark.driver.maxResultSize\" value : 4g - key : \"spark.driver.port\" value : 30055 - key : \"spark.blockManager.port\" value : 30060 - key : \"spark.driver.blockManager.port\" value : 30060 - key : \"spark.broadcast.port\" value : 30065 - key : \"spark.cores.max\" value : 20 - key : \"spark.rpc.message.maxSize\" value : 256 jarsPath : ../sparkjars serverClassPath : /mnt/PnTML/MF/lib/ parallel : 1 # threads of job lastScanSecond : 0.1 Reminder If the value of master included in engine.yaml is not \"local\" , users must copy the all of jars included in the sparkjars to the lib of the worker in each Spark Cluster. 1.2 Starting and Stopping MovingFeature Service MovingFeature service is started by executing the sh file. If the user can access to Moving Features Server, running the \" mfjson/bin/run_pntml.sh \" $ sh mfjson/bin/run_pntml.sh If the user can not access to Moving Features Server, running the \" mfjson/bin/run_noauth.sh \" $ sh mfjson/bin/run_noauth.sh If End product initialize is displayed on the screen, the boot is complete. Example of MovingFeature Service launch indication 2019 -04-05 15 :10:01.044 INFO 195 [ main ] o.a.c.m.s.connector.cassandra.Connector : Close connection. 2019 -04-05 15 :10:03.293 INFO 195 [ main ] o.a.c.m.s.connector.cassandra.Connector : Closed connection. 2019 -04-05 15 :10:03.296 INFO 195 [ main ] o.a.c.m.w.i.ProductionInitializer : End product initialize. Services performed in sh will stop at CTRL+C 2. Build Cassandra and set up extended libraries This document only describes the basic construction of Cassandra. Please visit Cassandra's website for detailed configuration and tuning. 2.1 Building Cassandra MovingFeature Service works with version 3.11.3 Cassandra. Download Cassandra Click this Download Cassandra Please download the version 3.11.3. wget http://archive.apache.org/dist/cassandra/3.11.3/apache-cassandra-3.11.3-bin.tar.gz Deploy the Cassandra Extract and deploy the downloaded tar.gz to your machine. Location can be anywhere, but a location with more storage capacity is recommended /home/mf/cassandra in this document. $ tar xzvf apache-cassandra-3.11.3-bin.tar.gz $ mv apache-cassandra-3.11.3 /home/mf/cassandra 2.2 Deployment of Stratio's Cassandra Lucene Index Library To use the Moving Feature Service, you must deploy the Library Stratio's Cassandra Lucene Index in Cassandra, which adds text search capabilities for Lucene. Please install the library as the same version with Cassandra. 2.2.1 Install the library from Maven Repository This library can be downloaded from the Maven Repository. Download the library from the Maven Repository website $ wget https://repo1.maven.org/maven2/com/stratio/cassandra/cassandra-lucene-index-plugin/3.11.3.0/cassandra-lucene-index-plugin-3.11.3.0.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp cassandra-lucene-index-plugin-3.11.3.0.jar /home/mf/cassandra/lib/ 2.2.2 Creating a Library from a Source This library can also be created from sources. Create from source using OpenJDK8, Git, and Maven. If it is not already installed, please install it. Obtaining Sources and Creating Libraries The source can be obtained from GitHub. You can get it from GitHub anywhere. $ git clone https://github.com/Stratio/cassandra-lucene-index.git Go to the created directory. $ cd cassandra-lucene-index Switch branch to branch-3.11.3 $ git checkout branch-3.11.3 Create a library. $ mvn clean package The library is created with the following name. The end of the version may vary depending on when you got it from GitHub. plugin/target/cassandra-lucene-index-plugin-3.11.3.1-RC1-SNAPSHOT.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp plugin/target/cassandra-lucene-index-plugin-3.11.3.1-RC1-SNAPSHOT.jar /home/mf/cassandra/lib/ 2.3 Deployment of JTS Topology Suite library Stratio's Cassandra Lucene Index library uses JTS Topology Suite library when handling location information. Since MovingFeature Service searches by location information, this library also needs to be placed in Cassandra. It must same the version of the library to the version required by Stratio's Cassandra Lucene Index. (As of April 8, 2019: jts-core-1.14.0.jar) This library can be downloaded from Maven Repository. Download the library from the Maven Repository website wget https://repo1.maven.org/maven2/com/vividsolutions/jts-core/1.14.0/jts-core-1.14.0.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp jts-core-1.14.0.jar /home/mf/cassandra/lib/ 3. Build Apache Spark This document only describes the basic construction of Apache Spark. Please visit Apache Spark's website for detailed configuration and tuning. 3.1 Build Apache Spark MovingFeature Service works with version 2.4.3 Apache Spark. Download Apache Spark Click this Download Apache Spark Please download the version 2.4.3 wget http://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz Deploy the Apache Spark Extract and deploy the downloaded tar.gz to your machine. Location can be anywhere, but a location with more storage capacity is recommended \" /home/mf/spark \" in this document. $ tar xzvf spark-2.4.3-bin-hadoop2.7.tgz $ sudo mv spark-2.4.3-bin-hadoop2.7/ /home/mf/spark 3.2 Set Apache Spark environment Set the Apache Spark execution path $ vim ~/.bashrc 2. Add the path of sprak in the \" ~/.bashrc \" export SPARK_HOME = /home/ mf/spark export PATH = $PATH:$SPARK_HOME /bin:$SPARK_HOME/ sbin 3. Activate the changes. $ source ~/.bashrc","title":"Getting Start"},{"location":"#getting-start","text":"This document describes the procedure for running MovingFeature Service.","title":"Getting Start"},{"location":"#1-procedure-for-executing-moving-feature-service","text":"This service will operate in the following environments: MovingFeature Service Running Environment","title":"1. Procedure for executing Moving Feature Service"},{"location":"#11-building-movingfeature-service","text":"This service is provided as a zip file. To extract the zip file from the machine on which the service runs. $ unzip mfjson.zip MovingFeature Service Directory Configuration MovingFeature Service File List Information for Service File","title":"1.1 Building MovingFeature Service"},{"location":"#111-to-set-up-a-web-configuration-file","text":"Web settings by editing the < mfjosn/bin/config/application.yaml >. Configuring Moving Features Service URLs Set the server address for the user to access the Moving Features Service. movingfeature : url : \"Moving Features Service URL\" Service URL Configuration Example","title":"1.1.1 To set up a Web configuration file"},{"location":"#112-to-set-up-a-store-configuration-file","text":"Store settings are done by editing < mfjson/bin/config/store.yaml >. Before configuring this configuration, create a Cassandra environment. Reference: Building 2 Cassandra and Configuring Extended Libraries. Configuring Cassandra to Connect Configure the connection destination for Cassandra to store data. nodes : - host : \"HostName or IP address\" port : \"Port Number\" Cassandra Configuration Example Access User Settings If you have limited access to Cassandra, you must configure a username and password for the user who can access it. authentication : user : \"UserName\" password : \"Password\"","title":"1.1.2 To set up a store configuration file"},{"location":"#113-to-set-up-a-engine-configuration-file","text":"Engine settings are done by editing < mfjson/bin/config/engine.yaml >. Before configuring this configuration, create a Apache Spark environment. Reference: Building 3 Apache Spark . Configuring Apache Spark to Connect Configure the connection destination for Cassandra to store data. Apache Spark Configuration Example Information of the setting items For more detailed information, please refer to the Spark Configuration section of the official document. Link for Spark Configuration spark : home : master : # Run Spark locally with as many worker threads as logical cores on your machine. appname : # The name of your application. This will appear in the UI and in log data. deploymode : # The deploy mode of Spark driver program, either \"client\" or \"cluster\", Which means to launch driver program locally (\"client\") or remotely (\"cluster\") on one of the nodes inside the cluster. verbose : # Print out fine-grained debugging information by running spark-submit conf : - key : \"spark.default.parallelism\" value : # Default number of partitions in RDDs returned by transformations like join, reduceByKey, and parallelize when not set by user - key : \"spark.executor.cores\" value : # Number of virtual cores - key : \"spark.executor.memory\" value : # Size of memory to use for each executor that runs the task - key : \"spark.driver.memory\" value : # Size of memory to use for the driver - key : \"spark.driver.cores\" value : # Number of virtual cores to use for the driver - key : \"spark.driver.maxResultSize\" value : # Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. Should be at least 1M, or 0 for unlimited. - key : \"spark.driver.port\" value : # Port for the driver to listen on - key : \"spark.blockManager.port\" value : # Port for all block managers to listen on - key : \"spark.driver.blockManager.port\" value : # Driver-specific port for the block manager to listen on, for cases where it cannot use the same configuration as executors. - key : \"spark.broadcast.port\" value : # Port for the driver's HTTP broadcast server to listen on. - key : \"spark.cores.max\" value : # The maximum amount of CPU cores to request for the application from across the cluster - key : \"spark.rpc.message.maxSize\" value : # Maximum message size (in MiB) to allow in \"control plane\" communication jarsPath : ../sparkjars serverClassPath : /mnt/PnTML/MF/lib/ parallel : 1 # threads of job lastScanSecond : 0.1 Example for configuration spark : home : master : local[*] appname : movingfeature- deploymode : client verbose : true conf : - key : \"spark.default.parallelism\" value : 20 - key : \"spark.executor.cores\" value : 2 - key : \"spark.executor.memory\" value : 10g - key : \"spark.driver.memory\" value : 10g - key : \"spark.driver.cores\" value : 2 - key : \"spark.driver.maxResultSize\" value : 4g - key : \"spark.driver.port\" value : 30055 - key : \"spark.blockManager.port\" value : 30060 - key : \"spark.driver.blockManager.port\" value : 30060 - key : \"spark.broadcast.port\" value : 30065 - key : \"spark.cores.max\" value : 20 - key : \"spark.rpc.message.maxSize\" value : 256 jarsPath : ../sparkjars serverClassPath : /mnt/PnTML/MF/lib/ parallel : 1 # threads of job lastScanSecond : 0.1 Reminder","title":"1.1.3 To set up a engine configuration file"},{"location":"#12-starting-and-stopping-movingfeature-service","text":"MovingFeature service is started by executing the sh file. If the user can access to Moving Features Server, running the \" mfjson/bin/run_pntml.sh \" $ sh mfjson/bin/run_pntml.sh If the user can not access to Moving Features Server, running the \" mfjson/bin/run_noauth.sh \" $ sh mfjson/bin/run_noauth.sh If End product initialize is displayed on the screen, the boot is complete. Example of MovingFeature Service launch indication 2019 -04-05 15 :10:01.044 INFO 195 [ main ] o.a.c.m.s.connector.cassandra.Connector : Close connection. 2019 -04-05 15 :10:03.293 INFO 195 [ main ] o.a.c.m.s.connector.cassandra.Connector : Closed connection. 2019 -04-05 15 :10:03.296 INFO 195 [ main ] o.a.c.m.w.i.ProductionInitializer : End product initialize. Services performed in sh will stop at CTRL+C","title":"1.2 Starting and Stopping MovingFeature Service"},{"location":"#2-build-cassandra-and-set-up-extended-libraries","text":"This document only describes the basic construction of Cassandra. Please visit Cassandra's website for detailed configuration and tuning.","title":"2. Build Cassandra and set up extended libraries"},{"location":"#21-building-cassandra","text":"MovingFeature Service works with version 3.11.3 Cassandra. Download Cassandra Click this Download Cassandra Please download the version 3.11.3. wget http://archive.apache.org/dist/cassandra/3.11.3/apache-cassandra-3.11.3-bin.tar.gz Deploy the Cassandra Extract and deploy the downloaded tar.gz to your machine. Location can be anywhere, but a location with more storage capacity is recommended /home/mf/cassandra in this document. $ tar xzvf apache-cassandra-3.11.3-bin.tar.gz $ mv apache-cassandra-3.11.3 /home/mf/cassandra","title":"2.1 Building Cassandra"},{"location":"#22-deployment-of-stratios-cassandra-lucene-index-library","text":"To use the Moving Feature Service, you must deploy the Library Stratio's Cassandra Lucene Index in Cassandra, which adds text search capabilities for Lucene. Please install the library as the same version with Cassandra.","title":"2.2 Deployment of Stratio's Cassandra Lucene Index Library"},{"location":"#221-install-the-library-from-maven-repository","text":"This library can be downloaded from the Maven Repository. Download the library from the Maven Repository website $ wget https://repo1.maven.org/maven2/com/stratio/cassandra/cassandra-lucene-index-plugin/3.11.3.0/cassandra-lucene-index-plugin-3.11.3.0.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp cassandra-lucene-index-plugin-3.11.3.0.jar /home/mf/cassandra/lib/","title":"2.2.1 Install the library from Maven Repository"},{"location":"#222-creating-a-library-from-a-source","text":"This library can also be created from sources. Create from source using OpenJDK8, Git, and Maven. If it is not already installed, please install it. Obtaining Sources and Creating Libraries The source can be obtained from GitHub. You can get it from GitHub anywhere. $ git clone https://github.com/Stratio/cassandra-lucene-index.git Go to the created directory. $ cd cassandra-lucene-index Switch branch to branch-3.11.3 $ git checkout branch-3.11.3 Create a library. $ mvn clean package The library is created with the following name. The end of the version may vary depending on when you got it from GitHub. plugin/target/cassandra-lucene-index-plugin-3.11.3.1-RC1-SNAPSHOT.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp plugin/target/cassandra-lucene-index-plugin-3.11.3.1-RC1-SNAPSHOT.jar /home/mf/cassandra/lib/","title":"2.2.2 Creating a Library from a Source"},{"location":"#23-deployment-of-jts-topology-suite-library","text":"Stratio's Cassandra Lucene Index library uses JTS Topology Suite library when handling location information. Since MovingFeature Service searches by location information, this library also needs to be placed in Cassandra. It must same the version of the library to the version required by Stratio's Cassandra Lucene Index. (As of April 8, 2019: jts-core-1.14.0.jar) This library can be downloaded from Maven Repository. Download the library from the Maven Repository website wget https://repo1.maven.org/maven2/com/vividsolutions/jts-core/1.14.0/jts-core-1.14.0.jar Library deployment Deployment of the downloaded library in Cassandra. The location is /lib/. In this document, it is deployed in \"/home/mf/cassandra/lib/\". $ cp jts-core-1.14.0.jar /home/mf/cassandra/lib/","title":"2.3 Deployment of JTS Topology Suite library"},{"location":"#3-build-apache-spark","text":"This document only describes the basic construction of Apache Spark. Please visit Apache Spark's website for detailed configuration and tuning.","title":"3. Build Apache Spark"},{"location":"#31-build-apache-spark","text":"MovingFeature Service works with version 2.4.3 Apache Spark. Download Apache Spark Click this Download Apache Spark Please download the version 2.4.3 wget http://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz Deploy the Apache Spark Extract and deploy the downloaded tar.gz to your machine. Location can be anywhere, but a location with more storage capacity is recommended \" /home/mf/spark \" in this document. $ tar xzvf spark-2.4.3-bin-hadoop2.7.tgz $ sudo mv spark-2.4.3-bin-hadoop2.7/ /home/mf/spark","title":"3.1 Build Apache Spark"},{"location":"#32-set-apache-spark-environment","text":"Set the Apache Spark execution path $ vim ~/.bashrc 2. Add the path of sprak in the \" ~/.bashrc \" export SPARK_HOME = /home/ mf/spark export PATH = $PATH:$SPARK_HOME /bin:$SPARK_HOME/ sbin 3. Activate the changes. $ source ~/.bashrc","title":"3.2 Set Apache Spark environment"}]}